{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ad4cd24-f241-4ee3-a517-d01774bcedfb",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/telmo-correa/nebulous-llm-experiment/blob/main/notebooks/1%20-%20Vector%20embedding.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0024ca22-4878-423b-baaa-fceec54f911b",
   "metadata": {},
   "source": [
    "### 1. Vector embedding\n",
    "\n",
    "This notebook demonstrates how to use langchain, OpenAI and Chroma to generate a Chroma DB containing vector embeddings for an arbitrary set of text files.\n",
    "\n",
    "Note that the data scraping for the data sources used by other notebooks in this repository is not included here; the pre-computed embeddings are made available for download when used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf3e492-e71a-4a6a-922a-375c93b6f437",
   "metadata": {},
   "outputs": [],
   "source": [
    "## If running on Google Colab, install the dependencies:\n",
    "\n",
    "%pip install openai langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd933546-ac47-4378-b567-0e18831d3595",
   "metadata": {},
   "source": [
    "Import libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b01a79-bf38-454f-b27f-63ab04bea25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "import getpass\n",
    "from tqdm import tqdm\n",
    "\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8231d6e2-517a-4782-83e1-c836eabeece2",
   "metadata": {},
   "source": [
    "Setup OpenAI API key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa41d61-6491-4cef-83eb-b47d6d744bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"OPENAI_API_KEY\" not in os.environ:\n",
    "    print(\"Please enter your OpenAI API key:\")\n",
    "    openai_api_key = getpass.getpass()\n",
    "\n",
    "    os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
    "    openai.api_key = openai_api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9046987e-3b66-4637-84c6-3970f210bc05",
   "metadata": {},
   "source": [
    "Setup input and output directories, chunk size, and chunk overlap:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd613b5e-d61f-4fcc-937d-3e4d1e91be0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIRECTORY = \"input_files/\"  # directory to read files from\n",
    "PERSIST_DIRECTORY = \"/tmp/chroma\"  # directory to persist the chroma DB\n",
    "\n",
    "CHUNK_SIZE = 1000                 # size of the chunk size used in each document\n",
    "CHUNK_OVERLAP = 150               # overlap size from consecutive chunk sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c69d805-c0fb-492c-b643-6a9b4cd99b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create text splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=CHUNK_SIZE, chunk_overlap=CHUNK_OVERLAP)\n",
    "\n",
    "# Create two lists to hold docs in memory\n",
    "all_texts = []\n",
    "all_metadata = []\n",
    "\n",
    "# Iterate through files\n",
    "for entry in tqdm(os.scandir(INPUT_DIRECTORY)):\n",
    "    if entry.is_dir():\n",
    "        continue\n",
    "\n",
    "    # Read file content\n",
    "    with open(entry.path) as f:\n",
    "        content = f.read()\n",
    "\n",
    "    # Split file into chunks\n",
    "    texts = text_splitter.split_text(content)\n",
    "\n",
    "    # Save chunks into list\n",
    "    all_texts += texts\n",
    "\n",
    "    # Save metadata for each chunk\n",
    "    all_metadata += [{\"source\": f\"{entry.name}_{i+1}\"} for i in range(len(texts))]\n",
    "\n",
    "print(\"Number of chunks: \", len(all_texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91d6fce-f21f-4e07-a6fc-d5804f29c5dc",
   "metadata": {},
   "source": [
    "Create OpenAI embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31802c48-11da-4f5b-abb4-facc92d58f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbefff23-faf9-4796-8f3d-a7a49e156097",
   "metadata": {},
   "source": [
    "Create ChromaDB, and persist it to the provided directory.\n",
    "\n",
    "**Note**: This will call OpenAI to generate embeddings for each text chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002e1028-cfce-4fb3-aaf4-2c0a8a2a063d",
   "metadata": {},
   "outputs": [],
   "source": [
    "docsearch = Chroma.from_texts(\n",
    "     texts=all_texts, \n",
    "     embedding=embedding, \n",
    "     metadatas=all_metadata,\n",
    "     persist_directory=PERSIST_DIRECTORY\n",
    ")\n",
    "docsearch.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d57310-3edd-41eb-b2bd-b7b8435c7adf",
   "metadata": {},
   "source": [
    "The embedding is now saved in the persist directory; we can compress it to a local file for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868b0b58-f24e-49ab-bd7b-61bcf2671077",
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo Compressing $PERSIST_DIRECTORY into chroma.tar.gz...\n",
    "!tar -cvzf chroma.tar.gz $PERSIST_DIRECTORY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75aae81c-2488-4738-a60b-65f53556c919",
   "metadata": {},
   "source": [
    "Display file info (make sure to download it / save it somewhere!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a4e1d0-2d17-4d8a-a9b5-9852e3fe885c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lh chroma.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706fee1f-75c8-4fec-8431-cef1383bc39d",
   "metadata": {},
   "source": [
    "Remove temporary persist directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1682b03-ebfb-4a32-9778-4aca27019a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf $PERSIST_DIRECTORY"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
